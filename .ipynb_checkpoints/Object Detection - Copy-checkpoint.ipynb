{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Conv2D, Reshape, Dense\n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas  Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train - Copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_paths = list(train_df['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_coords = np.zeros((train_df.shape[0],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "def extract_values(row):\n",
    "    global index\n",
    "    path, image_height, image_width, x0, y0, x1, y1, _, _ = row\n",
    "    my_coords[index, 0] = x0 * IMAGE_SIZE / image_width\n",
    "    my_coords[index, 1] = y0 * IMAGE_SIZE / image_height\n",
    "    my_coords[index, 2] = x1 * IMAGE_SIZE / image_width\n",
    "    my_coords[index, 3] = y1 * IMAGE_SIZE / image_height\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "5       None\n",
       "6       None\n",
       "7       None\n",
       "8       None\n",
       "9       None\n",
       "10      None\n",
       "11      None\n",
       "12      None\n",
       "13      None\n",
       "14      None\n",
       "15      None\n",
       "16      None\n",
       "17      None\n",
       "18      None\n",
       "19      None\n",
       "20      None\n",
       "21      None\n",
       "22      None\n",
       "23      None\n",
       "24      None\n",
       "25      None\n",
       "26      None\n",
       "27      None\n",
       "28      None\n",
       "29      None\n",
       "        ... \n",
       "2954    None\n",
       "2955    None\n",
       "2956    None\n",
       "2957    None\n",
       "2958    None\n",
       "2959    None\n",
       "2960    None\n",
       "2961    None\n",
       "2962    None\n",
       "2963    None\n",
       "2964    None\n",
       "2965    None\n",
       "2966    None\n",
       "2967    None\n",
       "2968    None\n",
       "2969    None\n",
       "2970    None\n",
       "2971    None\n",
       "2972    None\n",
       "2973    None\n",
       "2974    None\n",
       "2975    None\n",
       "2976    None\n",
       "2977    None\n",
       "2978    None\n",
       "2979    None\n",
       "2980    None\n",
       "2981    None\n",
       "2982    None\n",
       "2983    None\n",
       "Length: 2984, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.apply(extract_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124.32      ,  40.32      , 158.66666667,  88.48      ],\n",
       "       [ 43.008     ,  47.04      , 172.032     , 130.368     ],\n",
       "       [ 85.84771574,  31.808     , 190.45685279, 119.616     ],\n",
       "       ...,\n",
       "       [100.8       ,  60.54054054, 137.984     , 129.82582583],\n",
       "       [ 29.568     , 109.90933333, 128.576     , 196.52266667],\n",
       "       [ 42.56      ,  12.544     , 127.232     , 103.33866667]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.ceil(len(my_coords)/ BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- total=> 2984\n",
    "- 1 batch => 32 imgs\n",
    "- ceil(2984/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate Data in Batches\n",
    "\n",
    "# def data_generator(NUM_OF_PHOTO_PER_BATCH):\n",
    "    \n",
    "#     for id_, path in enumerate(my_paths):\n",
    "        \n",
    "    \n",
    "#         batch_paths = my_paths[id_*NUM_OF_PHOTO_PER_BATCH : (id_+1)*NUM_OF_PHOTO_PER_BATCH]\n",
    "#         batch_coords = my_coords[id_*NUM_OF_PHOTO_PER_BATCH : (id_+1)*NUM_OF_PHOTO_PER_BATCH]\n",
    "        \n",
    "#         batch_images = np.zeros((len(batch_paths), IMAGE_SIZE, IMAGE_SIZE, 3 )).astype(\"float32\")\n",
    "\n",
    "#         for i , f in enumerate(batch_paths):\n",
    "#             img = image.load_img(f, target_size=(IMAGE_SIZE, IMAGE_SIZE), color_mode='rgb')\n",
    "#             img = image.img_to_array(img)\n",
    "\n",
    "#             batch_images[i] = preprocess_input(img)\n",
    "        \n",
    "#         print(batch_images.shape)\n",
    "#         print(batch_coords.shape)\n",
    "#         if (id_+1)%32==0:\n",
    "#             yield [batch_images, batch_coords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data in one go\n",
    "\n",
    "def data_generator():\n",
    "    \n",
    "    batch_images = np.zeros((len(my_paths), IMAGE_SIZE, IMAGE_SIZE, 3 )).astype(\"float32\")\n",
    "    \n",
    "    \n",
    "    for id_, path in enumerate(my_paths):\n",
    "        \n",
    "        img = image.load_img(path, target_size=(IMAGE_SIZE, IMAGE_SIZE), color_mode='rgb')\n",
    "        img = image.img_to_array(img)\n",
    "\n",
    "        batch_images[id_] = preprocess_input(img)\n",
    "        if id_%100 == 0:\n",
    "            print(id_)\n",
    "        \n",
    "    return batch_images, my_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n"
     ]
    }
   ],
   "source": [
    "imgs, coo = data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"images.npy\", imgs)\n",
    "np.save(\"coordinates.npy\", coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.load(\"images.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo = np.load(\"coordinates.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    model = ResNet50(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=True)\n",
    "\n",
    "    # to freeze layers\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = model.layers[-2].output\n",
    "    x = Dense(4, name=\"coords\", activation='linear')(x)\n",
    "\n",
    "    model_new = Model(inputs=model.input, outputs=x)\n",
    "    return model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=\"mean_squared_error\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./model/weights-improvement-{epoch:02d}-{loss:.04f}-bigger.hdf5\"\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "earlystop = EarlyStopping(monitor='loss', min_delta=3, patience=5,verbose=1, mode='min', restore_best_weights=True)\n",
    "callbacks_list = [model_checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(generator=train_datagen,\n",
    "#                         epochs=EPOCHS,\n",
    "#                         steps_per_epoch= 1000,\n",
    "#                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2834 samples, validate on 150 samples\n",
      "Epoch 1/10\n",
      "2834/2834 [==============================] - 28s 10ms/step - loss: 665.7206 - acc: 0.7763 - val_loss: 983.3578 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00001: loss improved from 669.66786 to 665.72055, saving model to ./model/weights-improvement-01-665.7206-bigger.hdf5\n",
      "Epoch 2/10\n",
      "2834/2834 [==============================] - 24s 9ms/step - loss: 653.9291 - acc: 0.7791 - val_loss: 1012.7477 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00002: loss improved from 665.72055 to 653.92912, saving model to ./model/weights-improvement-02-653.9291-bigger.hdf5\n",
      "Epoch 3/10\n",
      "2834/2834 [==============================] - 25s 9ms/step - loss: 645.6979 - acc: 0.7830 - val_loss: 1018.6377 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00003: loss improved from 653.92912 to 645.69787, saving model to ./model/weights-improvement-03-645.6979-bigger.hdf5\n",
      "Epoch 4/10\n",
      "2834/2834 [==============================] - 25s 9ms/step - loss: 639.2160 - acc: 0.7837 - val_loss: 1015.5782 - val_acc: 0.6867\n",
      "\n",
      "Epoch 00004: loss improved from 645.69787 to 639.21599, saving model to ./model/weights-improvement-04-639.2160-bigger.hdf5\n",
      "Epoch 5/10\n",
      "2834/2834 [==============================] - 25s 9ms/step - loss: 635.2221 - acc: 0.7837 - val_loss: 1005.0766 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00005: loss improved from 639.21599 to 635.22206, saving model to ./model/weights-improvement-05-635.2221-bigger.hdf5\n",
      "Epoch 6/10\n",
      "2834/2834 [==============================] - 25s 9ms/step - loss: 622.1625 - acc: 0.7872 - val_loss: 1034.6529 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00006: loss improved from 635.22206 to 622.16247, saving model to ./model/weights-improvement-06-622.1625-bigger.hdf5\n",
      "Epoch 7/10\n",
      "2834/2834 [==============================] - 25s 9ms/step - loss: 626.2575 - acc: 0.7865 - val_loss: 1035.7019 - val_acc: 0.6933\n",
      "\n",
      "Epoch 00007: loss did not improve from 622.16247\n",
      "Epoch 8/10\n",
      "2834/2834 [==============================] - 25s 9ms/step - loss: 624.0072 - acc: 0.7904 - val_loss: 1036.2390 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00008: loss did not improve from 622.16247\n",
      "Epoch 9/10\n",
      "2834/2834 [==============================] - 25s 9ms/step - loss: 610.2704 - acc: 0.7925 - val_loss: 1029.2485 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00009: loss improved from 622.16247 to 610.27040, saving model to ./model/weights-improvement-09-610.2704-bigger.hdf5\n",
      "Epoch 10/10\n",
      "2834/2834 [==============================] - 25s 9ms/step - loss: 606.6116 - acc: 0.7922 - val_loss: 1021.2282 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00010: loss improved from 610.27040 to 606.61161, saving model to ./model/weights-improvement-10-606.6116-bigger.hdf5\n"
     ]
    }
   ],
   "source": [
    "his = model.fit(imgs, coo, batch_size=32, epochs=EPOCHS, callbacks=callbacks_list, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f8c3237c88>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(his.history['loss'])\n",
    "plt.plot(his.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(\"epochs40.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model/weights-improvement-30-669.6679-bigger.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = \"./images/Persian_132.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img in my_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = image.load_img(test_img, color_mode='rgb')\n",
    "i = image.img_to_array(i)\n",
    "i = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "i = i/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(test_img, target_size=(IMAGE_SIZE,IMAGE_SIZE), color_mode='rgb')\n",
    "img = image.img_to_array(img)\n",
    "\n",
    "img_fea = preprocess_input(img)\n",
    "img_fea = np.expand_dims(img_fea, axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = model.predict(x = img_fea)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 52.770367,  30.16234 , 246.71815 , 194.87389 ], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = int(region[0]* i.shape[1]/IMAGE_SIZE)\n",
    "y0 = int(region[1]* i.shape[0]/IMAGE_SIZE)\n",
    "\n",
    "x1 =  int(region[2]* i.shape[1]/IMAGE_SIZE)\n",
    "y1 =  int(region[3]* i.shape[0]/IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(i, (x0,y0), (x1,y1), (255,0,0), 2)\n",
    "cv2.imshow(\"image\", i)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
